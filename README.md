# face_recognition

### 데이터 구성 
110시간 분량의 총 6천개 영상 클립(AI hub 멀티모달 데이터)
클립당 1~3분 내외의 영상 파일과 메타데이터(JSON 포맷)
총 8종류의 감정, 감정의 강도 라벨링 데이터

1. 데이터 전처리
   - 동영상에서 프레임을 추출하고, Json 메타데이터에서 인물 객체, 감정 데이터를 파싱하여 매핑하였습니다.
   - 다양한 각도의 이미지 처리에 대한 어려움 : 동영상에서 추출한 이미지였기 떄문에 이미지 정합성이 떨어졌음, -> Data Argumentation을 통해 학습 품질 확보


2. CNN + Attention 기법을 결합하여 모델로 구성
   - ResNet18 모델 + pytorch의 Attention 모델을 결합하여 분류 모델 구성
   - Yolofacedetection 모델을 활용하여 인물 객체에서 얼굴만 추출하여 학습
  
3. Streamlit을 활용한 간단한 웹서비스 구축
